{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2695136a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T19:45:15.746456Z",
     "iopub.status.busy": "2025-07-13T19:45:15.746269Z",
     "iopub.status.idle": "2025-07-13T19:48:16.561934Z",
     "shell.execute_reply": "2025-07-13T19:48:16.559678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in /home/ervin-caravali-ibarra/Escritorio/ETL_FAST_AND_SAFE/venv/lib/python3.12/site-packages (2.0.41)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: greenlet>=1 in /home/ervin-caravali-ibarra/Escritorio/ETL_FAST_AND_SAFE/venv/lib/python3.12/site-packages (from sqlalchemy) (3.2.3)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /home/ervin-caravali-ibarra/Escritorio/ETL_FAST_AND_SAFE/venv/lib/python3.12/site-packages (from sqlalchemy) (4.14.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2\r\n",
      "  Using cached psycopg2-2.9.10.tar.gz (385 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Installing build dependencies ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \berror\r\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\r\n",
      "  \r\n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\r\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\r\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[34 lines of output]\u001b[0m\r\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-709wxty8/overlay/lib/python3.12/site-packages/setuptools/dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\r\n",
      "  \u001b[31m   \u001b[0m !!\r\n",
      "  \u001b[31m   \u001b[0m \r\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\r\n",
      "  \u001b[31m   \u001b[0m         Please consider removing the following classifiers in favor of a SPDX license expression:\r\n",
      "  \u001b[31m   \u001b[0m \r\n",
      "  \u001b[31m   \u001b[0m         License :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\r\n",
      "  \u001b[31m   \u001b[0m \r\n",
      "  \u001b[31m   \u001b[0m         See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\r\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\r\n",
      "  \u001b[31m   \u001b[0m \r\n",
      "  \u001b[31m   \u001b[0m !!\r\n",
      "  \u001b[31m   \u001b[0m   self._finalize_license_expression()\r\n",
      "  \u001b[31m   \u001b[0m running egg_info\r\n",
      "  \u001b[31m   \u001b[0m writing psycopg2.egg-info/PKG-INFO\r\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to psycopg2.egg-info/dependency_links.txt\r\n",
      "  \u001b[31m   \u001b[0m writing top-level names to psycopg2.egg-info/top_level.txt\r\n",
      "  \u001b[31m   \u001b[0m \r\n",
      "  \u001b[31m   \u001b[0m Error: pg_config executable not found.\r\n",
      "  \u001b[31m   \u001b[0m \r\n",
      "  \u001b[31m   \u001b[0m pg_config is required to build psycopg2 from source.  Please add the directory\r\n",
      "  \u001b[31m   \u001b[0m containing pg_config to the $PATH or specify the full executable path with the\r\n",
      "  \u001b[31m   \u001b[0m option:\r\n",
      "  \u001b[31m   \u001b[0m \r\n",
      "  \u001b[31m   \u001b[0m     python setup.py build_ext --pg-config /path/to/pg_config build ...\r\n",
      "  \u001b[31m   \u001b[0m \r\n",
      "  \u001b[31m   \u001b[0m or with the pg_config option in 'setup.cfg'.\r\n",
      "  \u001b[31m   \u001b[0m \r\n",
      "  \u001b[31m   \u001b[0m If you prefer to avoid building psycopg2 from source, please install the PyPI\r\n",
      "  \u001b[31m   \u001b[0m 'psycopg2-binary' package instead.\r\n",
      "  \u001b[31m   \u001b[0m \r\n",
      "  \u001b[31m   \u001b[0m For further information please check the 'doc/src/install.rst' file (also at\r\n",
      "  \u001b[31m   \u001b[0m <https://www.psycopg.org/docs/install.html>).\r\n",
      "  \u001b[31m   \u001b[0m \r\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\r\n",
      "  \r\n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\r\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\r\n",
      "\r\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\r\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\r\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\r\n",
      "\r\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /home/ervin-caravali-ibarra/Escritorio/ETL_FAST_AND_SAFE/venv/lib/python3.12/site-packages (2.9.10)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/ervin-caravali-ibarra/Escritorio/ETL_FAST_AND_SAFE/venv/lib/python3.12/site-packages (1.7.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.22.0 in /home/ervin-caravali-ibarra/Escritorio/ETL_FAST_AND_SAFE/venv/lib/python3.12/site-packages (from scikit-learn) (2.3.1)\r\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/ervin-caravali-ibarra/Escritorio/ETL_FAST_AND_SAFE/venv/lib/python3.12/site-packages (from scikit-learn) (1.16.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib>=1.2.0 in /home/ervin-caravali-ibarra/Escritorio/ETL_FAST_AND_SAFE/venv/lib/python3.12/site-packages (from scikit-learn) (1.5.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ervin-caravali-ibarra/Escritorio/ETL_FAST_AND_SAFE/venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/ervin-caravali-ibarra/Escritorio/ETL_FAST_AND_SAFE/venv/lib/python3.12/site-packages (2.3.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.26.0 in /home/ervin-caravali-ibarra/Escritorio/ETL_FAST_AND_SAFE/venv/lib/python3.12/site-packages (from pandas) (2.3.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ervin-caravali-ibarra/Escritorio/ETL_FAST_AND_SAFE/venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ervin-caravali-ibarra/Escritorio/ETL_FAST_AND_SAFE/venv/lib/python3.12/site-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ervin-caravali-ibarra/Escritorio/ETL_FAST_AND_SAFE/venv/lib/python3.12/site-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/ervin-caravali-ibarra/Escritorio/ETL_FAST_AND_SAFE/venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9628/1130646425.py:196: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  fact_serv['Tiempo_Mensajero_Asignado'] = pd.to_datetime(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verificación de datos temporales:\n",
      "Advertencia: Tiempo_Mensajero_Asignado tiene 1341629 valores nulos/inválidos\n",
      "Advertencia: Tiempo_Recogido_Origen tiene 103 valores nulos/inválidos\n",
      "Advertencia: Tiempo_Entregado_Destino tiene 103 valores nulos/inválidos\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumen final de valores nulos:\n",
      "ServicioKey                        0\n",
      "TiempoKey                          0\n",
      "ClienteKey                         0\n",
      "SedeOrigenKey                    246\n",
      "SedeDestinoKey                  2358\n",
      "MensajeroKey                   33530\n",
      "TipoServicio                       0\n",
      "EstadoServicio                     0\n",
      "EsFinal                            0\n",
      "Tiempo_Inicio                      0\n",
      "Tiempo_Mensajero_Asignado    1341629\n",
      "Tiempo_Recogido_Origen           103\n",
      "Tiempo_Entregado_Destino         103\n",
      "Mes                                0\n",
      "DiaSemana                          0\n",
      "Año                                0\n",
      "Hora                               0\n",
      "DiaMes                             0\n",
      "Duracion_Total_Min                 0\n",
      "Duracion_Asignacion_Min            0\n",
      "Duracion_Recogida_Min              0\n",
      "Duracion_Entrega_Min               0\n",
      "Duracion_Cierre_Min              103\n",
      "Eficiencia_Mensajero               0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Proceso completado exitosamente. Datos guardados en la tabla fact_servicios.\n"
     ]
    }
   ],
   "source": [
    "# Instalación de librerías requeridas\n",
    "%pip install sqlalchemy\n",
    "%pip install psycopg2\n",
    "%pip install psycopg2-binary\n",
    "%pip install scikit-learn\n",
    "%pip install pandas\n",
    "\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "with open('../../configBD/config.yml', 'r') as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "    cfg_etl = cfg['bodega']\n",
    "    cfg_bd = cfg['mensajeria']\n",
    "cfg_etl  # verificación rápida\n",
    "\n",
    "url_bd = f\"{cfg_bd['driver']}://{cfg_bd['user']}:{cfg_bd['password']}@{cfg_bd['host']}:{cfg_bd['port']}/{cfg_bd['db']}\"\n",
    "url_etl = f\"{cfg_etl['driver']}://{cfg_etl['user']}:{cfg_etl['password']}@{cfg_etl['host']}:{cfg_etl['port']}/{cfg_etl['db']}\"\n",
    "\n",
    "cliente_bd = create_engine(url_bd)     # base operativa\n",
    "cliente_etl = create_engine(url_etl)    # Data Warehouse\n",
    "\n",
    "# Carga de dimensiones\n",
    "dim_cliente = pd.read_sql_table('dim_cliente', url_etl)\n",
    "dim_mensajero = pd.read_sql_table('dim_mensajero', url_etl)\n",
    "dim_sede = pd.read_sql_table('dim_sede', url_etl)\n",
    "dim_tiempo = pd.read_sql_table('dim_tiempo', url_etl)\n",
    "\n",
    "# normaliza dim_tiempo → genera columna date\n",
    "dim_tiempo = dim_tiempo.rename(columns={'Año':'year','Mes':'month','Dia':'day'})\n",
    "dim_tiempo['date'] = pd.to_datetime(dim_tiempo[['year','month','day']]).dt.date\n",
    "\n",
    "# Carga de tablas operacionales\n",
    "servicios = pd.read_sql_table('mensajeria_servicio', url_bd)\n",
    "origenes = pd.read_sql_table('mensajeria_origenservicio', url_bd)\n",
    "destinos = pd.read_sql_table('mensajeria_destinoservicio', url_bd)\n",
    "estados_srv = pd.read_sql_table('mensajeria_estadosservicio', url_bd)\n",
    "cat_estado = pd.read_sql_table('mensajeria_estado', url_bd)\n",
    "cat_tipo_srv = pd.read_sql_table('mensajeria_tiposervicio', url_bd)\n",
    "\n",
    "# ----- 0) copia base -----\n",
    "fact_serv = servicios.copy()\n",
    "\n",
    "# ----- 1) TiempoKey (fecha_solicitud) -----\n",
    "fact_serv['FechaSolicitud'] = pd.to_datetime(fact_serv['fecha_solicitud']).dt.date\n",
    "dim_tiempo_subset = dim_tiempo[['tiempo_key','date']].rename(columns={'tiempo_key':'TiempoKey'})\n",
    "fact_serv = fact_serv.merge(dim_tiempo_subset,\n",
    "                          left_on='FechaSolicitud',\n",
    "                          right_on='date', how='left') \\\n",
    "                   .drop(columns=['date'])\n",
    "\n",
    "# ----- 2) FK Cliente -----\n",
    "fact_serv = fact_serv.merge(dim_cliente[['ClienteKey','cliente_id']],\n",
    "                          on='cliente_id', how='left')\n",
    "\n",
    "# ----- 3) FK Mensajero (titular) -----\n",
    "fact_serv = fact_serv.merge(dim_mensajero[['MensajeroKey','user_id']],\n",
    "                          left_on='mensajero_id', right_on='user_id',\n",
    "                          how='left').drop(columns=['user_id'])\n",
    "\n",
    "# ----- 4) FK Sede Origen y Destino -----\n",
    "# 4a) unir origen\n",
    "fact_serv = (\n",
    "    fact_serv\n",
    "    .merge(\n",
    "        origenes[['id','cliente_id','ciudad_id']],\n",
    "        left_on='origen_id', right_on='id',\n",
    "        how='left',\n",
    "        suffixes=('','_ori')\n",
    "    )\n",
    "    .rename(columns={\n",
    "        'ciudad_id': 'ciudad_ori',\n",
    "        'cliente_id_ori': 'cliente_ori'\n",
    "    })\n",
    "    .drop(columns=['id_ori'])\n",
    ")\n",
    "\n",
    "# 4b) unir destino\n",
    "fact_serv = (\n",
    "    fact_serv\n",
    "    .merge(\n",
    "        destinos[['id','cliente_id','ciudad_id']],\n",
    "        left_on='destino_id', right_on='id',\n",
    "        how='left',\n",
    "        suffixes=('','_des')\n",
    "    )\n",
    "    .rename(columns={\n",
    "        'ciudad_id': 'ciudad_des',\n",
    "        'cliente_id_des': 'cliente_des'\n",
    "    })\n",
    "    .drop(columns=['id_des'])\n",
    ")\n",
    "\n",
    "# 4c) lookup en dim_sede para SedeOrigenKey\n",
    "fact_serv = (\n",
    "    fact_serv\n",
    "    .merge(\n",
    "        dim_sede[['SedeKey','ciudad_id','cliente_id']],\n",
    "        left_on=['ciudad_ori','cliente_ori'],\n",
    "        right_on=['ciudad_id','cliente_id'],\n",
    "        how='left',\n",
    "        suffixes=('','_dim')\n",
    "    )\n",
    "    .rename(columns={'SedeKey':'SedeOrigenKey'})\n",
    "    .drop(columns=['ciudad_id','cliente_id_dim'])\n",
    ")\n",
    "\n",
    "# 4d) lookup en dim_sede para SedeDestinoKey\n",
    "fact_serv = (\n",
    "    fact_serv\n",
    "    .merge(\n",
    "        dim_sede[['SedeKey','ciudad_id','cliente_id']],\n",
    "        left_on=['ciudad_des','cliente_des'],\n",
    "        right_on=['ciudad_id','cliente_id'],\n",
    "        how='left',\n",
    "        suffixes=('','_dim')\n",
    "    )\n",
    "    .rename(columns={'SedeKey':'SedeDestinoKey'})\n",
    "    .drop(columns=['ciudad_id','cliente_id_dim'])\n",
    ")\n",
    "\n",
    "# ----- 5) TipoServicio -----\n",
    "fact_serv = (\n",
    "    fact_serv\n",
    "    .merge(\n",
    "        cat_tipo_srv[['id','nombre']],\n",
    "        left_on='tipo_servicio_id',\n",
    "        right_on='id',\n",
    "        how='left',\n",
    "        suffixes=('','_tipo')\n",
    "    )\n",
    "    .rename(columns={'nombre':'TipoServicio'})\n",
    "    .drop(columns=['id_tipo'])\n",
    ")\n",
    "\n",
    "# ----- 6) EstadoServicio (último estado registrado) -----\n",
    "# 6a) fusionar nombre del estado\n",
    "estados_srv = (\n",
    "    estados_srv\n",
    "    .merge(\n",
    "        cat_estado[['id','nombre']],\n",
    "        left_on='estado_id',\n",
    "        right_on='id',\n",
    "        how='left',\n",
    "        suffixes=('','_cat')\n",
    "    )\n",
    "    .rename(columns={'nombre':'EstadoNom'})\n",
    "    .drop(columns=['id_cat'])\n",
    ")\n",
    "\n",
    "# Eliminar columnas duplicadas\n",
    "estados_srv = estados_srv.loc[:, ~estados_srv.columns.duplicated()]\n",
    "\n",
    "# 6b) timestamp con microsegundos\n",
    "estados_srv['timestamp'] = pd.to_datetime(\n",
    "    estados_srv['fecha'].astype(str) + ' ' + estados_srv['hora'].astype(str),\n",
    "    format='%Y-%m-%d %H:%M:%S.%f',\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# 6c) extraer último estado\n",
    "ult_estado = (\n",
    "    estados_srv\n",
    "    .sort_values('timestamp')\n",
    "    .groupby('servicio_id', as_index=False)\n",
    "    .tail(1)[['servicio_id','EstadoNom','timestamp']]\n",
    ")\n",
    "\n",
    "# 6d) merge en fact_serv\n",
    "fact_serv = (\n",
    "    fact_serv\n",
    "    .merge(ult_estado,\n",
    "          left_on='id', right_on='servicio_id',\n",
    "          how='left')\n",
    "    .rename(columns={'EstadoNom':'EstadoServicio'})\n",
    "    .drop(columns=['servicio_id'])\n",
    ")\n",
    "\n",
    "# Eliminar columnas duplicadas\n",
    "fact_serv = fact_serv.loc[:, ~fact_serv.columns.duplicated()]\n",
    "\n",
    "# ----- 7) EsFinal (TRUE si el estado es uno de los finales) -----\n",
    "finales = ['Entregado en destino', 'Terminado completo',]\n",
    "fact_serv['EsFinal'] = fact_serv['EstadoServicio'].isin(finales)\n",
    "\n",
    "# ----- 8) Timestamps de tracking alternativos -----\n",
    "# 8.1) Inicio = fecha_solicitud + hora_solicitud\n",
    "fact_serv['Tiempo_Inicio'] = pd.to_datetime(\n",
    "    fact_serv['fecha_solicitud'].astype(str) + ' ' +\n",
    "    fact_serv['hora_solicitud'].astype(str),\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# 8.2) Asignado = fecha_solicitud + hora_visto_por_mensajero\n",
    "fact_serv['Tiempo_Mensajero_Asignado'] = pd.to_datetime(\n",
    "    fact_serv['fecha_solicitud'].astype(str) + ' ' +\n",
    "    fact_serv['hora_visto_por_mensajero'].astype(str),\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# 8.3) Recogido = fecha_deseada + hora_deseada\n",
    "fact_serv['Tiempo_Recogido_Origen'] = pd.to_datetime(\n",
    "    fact_serv['fecha_deseada'].astype(str) + ' ' +\n",
    "    fact_serv['hora_deseada'].astype(str),\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# 8.4) Entregado = Recogido + horas según prioridad\n",
    "priority_hours = {\n",
    "    'Alta: En una Hora': 1,\n",
    "    'Media: De 1 a 3 horas': 2,\n",
    "    'Media: De 1 - 3 Horas': 2,\n",
    "    'Baja: Transcurso del Dia': 8\n",
    "}\n",
    "fact_serv['Tiempo_Entregado_Destino'] = (\n",
    "    fact_serv['Tiempo_Recogido_Origen'] +\n",
    "    fact_serv['prioridad']\n",
    "             .map(priority_hours)\n",
    "             .fillna(1)\n",
    "             .apply(lambda h: pd.Timedelta(hours=h))\n",
    ")\n",
    "\n",
    "fact_serv['Minutos_Entregado'] = fact_serv['Tiempo_Entregado_Destino'].dt.minute\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----- Verificación y limpieza de datos temporales -----\n",
    "print(\"\\nVerificación de datos temporales:\")\n",
    "for col in ['Tiempo_Inicio', 'Tiempo_Mensajero_Asignado', 'Tiempo_Recogido_Origen', 'Tiempo_Entregado_Destino']:\n",
    "    # Convertir a datetime y manejar valores inválidos\n",
    "    fact_serv[col] = pd.to_datetime(fact_serv[col], errors='coerce')\n",
    "    \n",
    "    # Verificar si hay valores nulos\n",
    "    null_count = fact_serv[col].isnull().sum()\n",
    "    if null_count > 0:\n",
    "        print(f\"Advertencia: {col} tiene {null_count} valores nulos/inválidos\")\n",
    "\n",
    "# ----- Cálculo robusto de duraciones -----\n",
    "def calcular_duracion(inicio, fin):\n",
    "    try:\n",
    "        # Verificar que ambos valores no sean nulos\n",
    "        if pd.isnull(inicio) or pd.isnull(fin):\n",
    "            return None\n",
    "        \n",
    "        # Calcular diferencia en minutos\n",
    "        diff = (fin - inicio).total_seconds() / 60\n",
    "        \n",
    "        # Asegurar que no sea negativo\n",
    "        return max(0, diff) if pd.notnull(diff) else None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Calcular cada duración con manejo de errores\n",
    "fact_serv['Duracion_Total_Min'] = fact_serv.apply(\n",
    "    lambda x: calcular_duracion(x['Tiempo_Inicio'], x['Tiempo_Entregado_Destino']), axis=1\n",
    ").round(2)\n",
    "\n",
    "fact_serv['Duracion_Asignacion_Min'] = fact_serv.apply(\n",
    "    lambda x: calcular_duracion(x['Tiempo_Inicio'], x['Tiempo_Mensajero_Asignado']), axis=1\n",
    ").round(2)\n",
    "\n",
    "fact_serv['Duracion_Recogida_Min'] = fact_serv.apply(\n",
    "    lambda x: calcular_duracion(x['Tiempo_Mensajero_Asignado'], x['Tiempo_Recogido_Origen']), axis=1\n",
    ").round(2)\n",
    "\n",
    "fact_serv['Duracion_Entrega_Min'] = fact_serv.apply(\n",
    "    lambda x: calcular_duracion(x['Tiempo_Recogido_Origen'], x['Tiempo_Entregado_Destino']), axis=1\n",
    ").round(2)\n",
    "\n",
    "fact_serv['Duracion_Cierre_Min'] = fact_serv.apply(\n",
    "    lambda x: calcular_duracion(x['Tiempo_Inicio'], x['Tiempo_Entregado_Destino']), axis=1\n",
    ").round(2)\n",
    "\n",
    "# ----- Cálculo de eficiencia con manejo de valores nulos -----\n",
    "# Primero calcular el promedio de duración por mensajero\n",
    "avg_duracion_por_mensajero = fact_serv.groupby('MensajeroKey')['Duracion_Total_Min'].transform('mean')\n",
    "\n",
    "# Calcular eficiencia con manejo de nulos\n",
    "fact_serv['Eficiencia_Mensajero'] = fact_serv.apply(\n",
    "    lambda x: (x['Duracion_Total_Min'] / avg_duracion_por_mensajero[x.name]).round(2) \n",
    "    if pd.notnull(x['Duracion_Total_Min']) and pd.notnull(avg_duracion_por_mensajero[x.name]) \n",
    "    else None, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Imputar valores nulos para duraciones (usando la mediana)\n",
    "for col in ['Duracion_Total_Min', 'Duracion_Asignacion_Min', 'Duracion_Recogida_Min', 'Duracion_Entrega_Min']:\n",
    "    median_val = fact_serv[col].median()\n",
    "    fact_serv[col] = fact_serv[col].fillna(median_val)\n",
    "\n",
    "# Para eficiencia, imputar 1.0 (valor neutral)\n",
    "fact_serv['Eficiencia_Mensajero'] = fact_serv['Eficiencia_Mensajero'].fillna(1.0)\n",
    "\n",
    "# ----- Añadir nuevas columnas temporales -----\n",
    "# 1) Columnas temporales para análisis\n",
    "fact_serv['Mes'] = pd.to_datetime(fact_serv['Tiempo_Inicio']).dt.month_name()\n",
    "fact_serv['DiaSemana'] = pd.to_datetime(fact_serv['Tiempo_Inicio']).dt.day_name()\n",
    "fact_serv['Año'] = pd.to_datetime(fact_serv['Tiempo_Inicio']).dt.year\n",
    "fact_serv['Hora'] = pd.to_datetime(fact_serv['Tiempo_Inicio']).dt.hour\n",
    "fact_serv['DiaMes'] = pd.to_datetime(fact_serv['Tiempo_Inicio']).dt.day\n",
    "\n",
    "# ----- 9) limpieza de columnas intermedias -----\n",
    "drop_cols = (\n",
    "    [c for c in fact_serv.columns if c.startswith(('fecha_','hora_','ciudad_','cliente_'))]\n",
    "    + ['servicio_id']\n",
    ")\n",
    "fact_serv = fact_serv.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "# 0) renombra el PK para que sea ServicioKey\n",
    "fact_serv = fact_serv.rename(columns={'id':'ServicioKey'})\n",
    "\n",
    "# Definición de columnas finales incluyendo las nuevas métricas\n",
    "cols_final = [\n",
    "    'ServicioKey', 'TiempoKey', 'ClienteKey', 'SedeOrigenKey', 'SedeDestinoKey',\n",
    "    'MensajeroKey', 'TipoServicio', 'EstadoServicio', 'EsFinal',\n",
    "    'Tiempo_Inicio', 'Tiempo_Mensajero_Asignado', 'Tiempo_Recogido_Origen',\n",
    "    'Tiempo_Entregado_Destino',\n",
    "    'Mes', 'DiaSemana', 'Año', 'Hora', 'DiaMes',  # Columnas temporales\n",
    "    'Duracion_Total_Min', 'Duracion_Asignacion_Min', 'Duracion_Recogida_Min',\n",
    "    'Duracion_Entrega_Min', 'Duracion_Cierre_Min', # Métricas de duración\n",
    "    'Eficiencia_Mensajero'  # Indicador de eficiencia\n",
    "]\n",
    "\n",
    "# Seleccionar solo las columnas finales\n",
    "fact_serv = fact_serv[cols_final]\n",
    "\n",
    "# Verificación final de valores nulos\n",
    "print(\"\\nResumen final de valores nulos:\")\n",
    "print(fact_serv.isnull().sum())\n",
    "\n",
    "# Subconjunto de 5 000 filas\n",
    "fact_serv_sub = fact_serv.head(5000)\n",
    "\n",
    "# Reset de transacción y volcado\n",
    "raw = cliente_etl.raw_connection()\n",
    "raw.rollback()\n",
    "raw.close()\n",
    "\n",
    "# Guardar en la base de datos\n",
    "fact_serv_sub.to_sql(\n",
    "    'fact_servicios',\n",
    "    cliente_etl,\n",
    "    if_exists='replace',\n",
    "    index=False,\n",
    "    method='multi',\n",
    "    chunksize=1000\n",
    ")\n",
    "\n",
    "print(\"\\nProceso completado exitosamente. Datos guardados en la tabla fact_servicios.\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
