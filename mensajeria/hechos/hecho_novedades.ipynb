{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c9bc1de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:21:49.044152Z",
     "start_time": "2024-11-05T13:21:47.885989Z"
    },
    "execution": {
     "iopub.execute_input": "2025-07-13T19:48:19.806204Z",
     "iopub.status.busy": "2025-07-13T19:48:19.805760Z",
     "iopub.status.idle": "2025-07-13T19:48:20.424634Z",
     "shell.execute_reply": "2025-07-13T19:48:20.424091Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e5ebef0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:21:54.451066Z",
     "start_time": "2024-11-05T13:21:49.070058Z"
    },
    "execution": {
     "iopub.execute_input": "2025-07-13T19:48:20.426657Z",
     "iopub.status.busy": "2025-07-13T19:48:20.426409Z",
     "iopub.status.idle": "2025-07-13T19:48:29.207817Z",
     "shell.execute_reply": "2025-07-13T19:48:29.206460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in /home/ervin-caravali-ibarra/Escritorio/ETL_FAST_AND_SAFE/venv/lib/python3.12/site-packages (2.0.41)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: greenlet>=1 in /home/ervin-caravali-ibarra/Escritorio/ETL_FAST_AND_SAFE/venv/lib/python3.12/site-packages (from sqlalchemy) (3.2.3)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /home/ervin-caravali-ibarra/Escritorio/ETL_FAST_AND_SAFE/venv/lib/python3.12/site-packages (from sqlalchemy) (4.14.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/ervin-caravali-ibarra/Escritorio/ETL_FAST_AND_SAFE/venv/lib/python3.12/site-packages (2.3.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.26.0 in /home/ervin-caravali-ibarra/Escritorio/ETL_FAST_AND_SAFE/venv/lib/python3.12/site-packages (from pandas) (2.3.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ervin-caravali-ibarra/Escritorio/ETL_FAST_AND_SAFE/venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ervin-caravali-ibarra/Escritorio/ETL_FAST_AND_SAFE/venv/lib/python3.12/site-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ervin-caravali-ibarra/Escritorio/ETL_FAST_AND_SAFE/venv/lib/python3.12/site-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/ervin-caravali-ibarra/Escritorio/ETL_FAST_AND_SAFE/venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2\r\n",
      "  Using cached psycopg2-2.9.10.tar.gz (385 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Installing build dependencies ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \berror\r\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\r\n",
      "  \r\n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\r\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\r\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[34 lines of output]\u001b[0m\r\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-kolbkf6m/overlay/lib/python3.12/site-packages/setuptools/dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\r\n",
      "  \u001b[31m   \u001b[0m !!\r\n",
      "  \u001b[31m   \u001b[0m \r\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\r\n",
      "  \u001b[31m   \u001b[0m         Please consider removing the following classifiers in favor of a SPDX license expression:\r\n",
      "  \u001b[31m   \u001b[0m \r\n",
      "  \u001b[31m   \u001b[0m         License :: OSI Approved :: GNU Library or Lesser General Public License (LGPL)\r\n",
      "  \u001b[31m   \u001b[0m \r\n",
      "  \u001b[31m   \u001b[0m         See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\r\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\r\n",
      "  \u001b[31m   \u001b[0m \r\n",
      "  \u001b[31m   \u001b[0m !!\r\n",
      "  \u001b[31m   \u001b[0m   self._finalize_license_expression()\r\n",
      "  \u001b[31m   \u001b[0m running egg_info\r\n",
      "  \u001b[31m   \u001b[0m writing psycopg2.egg-info/PKG-INFO\r\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to psycopg2.egg-info/dependency_links.txt\r\n",
      "  \u001b[31m   \u001b[0m writing top-level names to psycopg2.egg-info/top_level.txt\r\n",
      "  \u001b[31m   \u001b[0m \r\n",
      "  \u001b[31m   \u001b[0m Error: pg_config executable not found.\r\n",
      "  \u001b[31m   \u001b[0m \r\n",
      "  \u001b[31m   \u001b[0m pg_config is required to build psycopg2 from source.  Please add the directory\r\n",
      "  \u001b[31m   \u001b[0m containing pg_config to the $PATH or specify the full executable path with the\r\n",
      "  \u001b[31m   \u001b[0m option:\r\n",
      "  \u001b[31m   \u001b[0m \r\n",
      "  \u001b[31m   \u001b[0m     python setup.py build_ext --pg-config /path/to/pg_config build ...\r\n",
      "  \u001b[31m   \u001b[0m \r\n",
      "  \u001b[31m   \u001b[0m or with the pg_config option in 'setup.cfg'.\r\n",
      "  \u001b[31m   \u001b[0m \r\n",
      "  \u001b[31m   \u001b[0m If you prefer to avoid building psycopg2 from source, please install the PyPI\r\n",
      "  \u001b[31m   \u001b[0m 'psycopg2-binary' package instead.\r\n",
      "  \u001b[31m   \u001b[0m \r\n",
      "  \u001b[31m   \u001b[0m For further information please check the 'doc/src/install.rst' file (also at\r\n",
      "  \u001b[31m   \u001b[0m <https://www.psycopg.org/docs/install.html>).\r\n",
      "  \u001b[31m   \u001b[0m \r\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\r\n",
      "  \r\n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\r\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\r\n",
      "\r\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\r\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\r\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\r\n",
      "\r\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /home/ervin-caravali-ibarra/Escritorio/ETL_FAST_AND_SAFE/venv/lib/python3.12/site-packages (2.9.10)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: holidays in /home/ervin-caravali-ibarra/Escritorio/ETL_FAST_AND_SAFE/venv/lib/python3.12/site-packages (0.76)\r\n",
      "Requirement already satisfied: python-dateutil in /home/ervin-caravali-ibarra/Escritorio/ETL_FAST_AND_SAFE/venv/lib/python3.12/site-packages (from holidays) (2.9.0.post0)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/ervin-caravali-ibarra/Escritorio/ETL_FAST_AND_SAFE/venv/lib/python3.12/site-packages (from python-dateutil->holidays) (1.17.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Instala SQLAlchemy para manejar la conexión a bases de datos y mapear datos tabulares en Python.\n",
    "%pip install sqlalchemy\n",
    "\n",
    "# Instala pandas para cargar, manipular, transformar y analizar los datos.\n",
    "%pip install pandas\n",
    "\n",
    "# Instala psycopg2 para interactuar con bases de datos PostgreSQL.\n",
    "%pip install psycopg2\n",
    "\n",
    "# Instala psycopg2-binary, la versión binaria, para facilitar la interacción con PostgreSQL.\n",
    "%pip install psycopg2-binary\n",
    "\n",
    "# Instala la biblioteca holidays para considerar feriados en el análisis de datos o procesamiento de fechas.\n",
    "%pip install holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0863b60c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:21:54.518804Z",
     "start_time": "2024-11-05T13:21:54.506667Z"
    },
    "execution": {
     "iopub.execute_input": "2025-07-13T19:48:29.210016Z",
     "iopub.status.busy": "2025-07-13T19:48:29.209785Z",
     "iopub.status.idle": "2025-07-13T19:48:29.220070Z",
     "shell.execute_reply": "2025-07-13T19:48:29.219215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'driver': 'postgresql+psycopg2',\n",
       " 'host': 'proyectobodega.postgres.database.azure.com',\n",
       " 'port': 5432,\n",
       " 'user': 'adminbodega',\n",
       " 'password': 'Goddess9039',\n",
       " 'db': 'proyectobodega'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Abrimos el archivo YAML de configuración ubicado en el directorio '../../configBD/config.yml'.\n",
    "# Este archivo contiene los parámetros de conexión a la base de datos.\n",
    "with open('../../configBD/config.yml', 'r') as f:\n",
    "    # Cargamos el archivo YAML usando la función safe_load de la librería 'yaml'.\n",
    "    # Esto convierte el contenido del archivo en un diccionario de Python.\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "    # Extraemos la configuración específica para la base de datos 'bodega'.\n",
    "    # Se asume que el archivo YAML tiene una sección llamada 'bodega' con los detalles de conexión.\n",
    "    config_etl = config['bodega']\n",
    "    config_bd  = config['mensajeria']\n",
    "\n",
    "config_etl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5efb094",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:21:54.531828Z",
     "start_time": "2024-11-05T13:21:54.528427Z"
    },
    "execution": {
     "iopub.execute_input": "2025-07-13T19:48:29.222391Z",
     "iopub.status.busy": "2025-07-13T19:48:29.222197Z",
     "iopub.status.idle": "2025-07-13T19:48:29.226454Z",
     "shell.execute_reply": "2025-07-13T19:48:29.225959Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'postgresql://postgres:Ec94@localhost:5432/proyecto'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construimos la URL de conexión a la base de datos usando los parámetros extraídos del archivo YAML.\n",
    "# Esta URL sigue el formato estándar de SQLAlchemy: 'driver://user:password@host:port/dbname'.\n",
    "url_bd = (f\"{config_bd['driver']}://{config_bd['user']}:{config_bd['password']}@{config_bd['host']}:\"\n",
    "          f\"{config_bd['port']}/{config_bd['db']}\")\n",
    "url_bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84ff87c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:21:54.547655Z",
     "start_time": "2024-11-05T13:21:54.541726Z"
    },
    "execution": {
     "iopub.execute_input": "2025-07-13T19:48:29.228723Z",
     "iopub.status.busy": "2025-07-13T19:48:29.228407Z",
     "iopub.status.idle": "2025-07-13T19:48:29.232441Z",
     "shell.execute_reply": "2025-07-13T19:48:29.231950Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'postgresql+psycopg2://adminbodega:Goddess9039@proyectobodega.postgres.database.azure.com:5432/proyectobodega'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_etl = (f\"{config_etl['driver']}://{config_etl['user']}:{config_etl['password']}@{config_etl['host']}:\"\n",
    "           f\"{config_etl['port']}/{config_etl['db']}\")\n",
    "url_etl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a1465ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:21:54.606436Z",
     "start_time": "2024-11-05T13:21:54.556390Z"
    },
    "execution": {
     "iopub.execute_input": "2025-07-13T19:48:29.235281Z",
     "iopub.status.busy": "2025-07-13T19:48:29.234768Z",
     "iopub.status.idle": "2025-07-13T19:48:29.296279Z",
     "shell.execute_reply": "2025-07-13T19:48:29.294740Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creamos el motor de conexión a la base de datos usando SQLAlchemy.\n",
    "# El motor de conexión se usa para ejecutar consultas y transacciones en la base de datos.\n",
    "cliente_bd  = create_engine(url_bd)\n",
    "cliente_etl = create_engine(url_etl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b746287",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:21:54.760191Z",
     "start_time": "2024-11-05T13:21:54.613178Z"
    },
    "execution": {
     "iopub.execute_input": "2025-07-13T19:48:29.298429Z",
     "iopub.status.busy": "2025-07-13T19:48:29.298188Z",
     "iopub.status.idle": "2025-07-13T19:48:46.409259Z",
     "shell.execute_reply": "2025-07-13T19:48:46.407832Z"
    }
   },
   "outputs": [],
   "source": [
    "dim_mensajero = pd.read_sql_table('dim_mensajero', url_etl)\n",
    "dim_cliente = pd.read_sql_table('dim_cliente', url_etl)\n",
    "dim_sede = pd.read_sql_table('dim_sede', url_etl)\n",
    "dim_tiempo = pd.read_sql_table('dim_tiempo', url_etl)\n",
    "# Catálogo y tablas operativas\n",
    "cat_tipo_nov = pd.read_sql_table('mensajeria_tiponovedad', url_bd)\n",
    "servicios = pd.read_sql_table('mensajeria_servicio', url_bd)\n",
    "destinos = pd.read_sql_table('mensajeria_destinoservicio', url_bd) \n",
    "medidas_tiempo = pd.read_sql_table('clientes_mensajeroaquitoy', url_bd)\n",
    "# si tu servicio apunta a destino\\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b9853ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:21:54.992179Z",
     "start_time": "2024-11-05T13:21:54.770248Z"
    },
    "execution": {
     "iopub.execute_input": "2025-07-13T19:48:46.412547Z",
     "iopub.status.busy": "2025-07-13T19:48:46.412040Z",
     "iopub.status.idle": "2025-07-13T19:48:46.672790Z",
     "shell.execute_reply": "2025-07-13T19:48:46.672204Z"
    }
   },
   "outputs": [],
   "source": [
    "novedades = pd.read_sql_table('mensajeria_novedadesservicio', url_bd)\n",
    "novedades['fecha_novedad'] = pd.to_datetime(novedades['fecha_novedad']).dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14c3c1f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T19:48:46.674788Z",
     "iopub.status.busy": "2025-07-13T19:48:46.674608Z",
     "iopub.status.idle": "2025-07-13T19:48:46.793138Z",
     "shell.execute_reply": "2025-07-13T19:48:46.792636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas en cat_tipo_nov: ['id', 'nombre']\n",
      "['id_x', 'fecha_novedad', 'tipo_novedad_id', 'descripcion', 'servicio_id', 'es_prueba', 'mensajero_id', 'TiempoReporte', 'TiempoKey', 'id_y', 'destino_id_lookup', 'cliente_id_serv']\n",
      "['id_x', 'fecha_novedad', 'tipo_novedad_id', 'descripcion', 'servicio_id', 'es_prueba', 'mensajero_id', 'TiempoReporte', 'TiempoKey', 'id_y', 'destino_id_lookup', 'cliente_id_serv', 'id', 'ciudad_id_lookup', 'cliente_id_lookup']\n",
      "['id_x', 'fecha_novedad', 'tipo_novedad_id', 'descripcion', 'servicio_id', 'es_prueba', 'mensajero_id', 'TiempoReporte', 'TiempoKey', 'id_y', 'destino_id_lookup', 'cliente_id_serv', 'id', 'ciudad_id_lookup', 'cliente_id_lookup', 'TipoNovedad', 'Gravedad', 'ClienteKey']\n",
      "['id_x', 'fecha_novedad', 'tipo_novedad_id', 'descripcion', 'servicio_id', 'es_prueba', 'mensajero_id', 'TiempoReporte', 'TiempoKey', 'id_y', 'destino_id_lookup', 'cliente_id_serv', 'id', 'ciudad_id_lookup', 'cliente_id_lookup', 'TipoNovedad', 'Gravedad', 'ClienteKey', 'SedeKey']\n",
      "['id_x', 'fecha_novedad', 'tipo_novedad_id', 'descripcion', 'servicio_id', 'es_prueba', 'mensajero_id', 'TiempoReporte', 'TiempoKey', 'id_y', 'destino_id_lookup', 'cliente_id_serv', 'id', 'ciudad_id_lookup', 'cliente_id_lookup', 'TipoNovedad', 'Gravedad', 'ClienteKey', 'SedeKey', 'MensajeroKey', 'user_id']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10407/3240190489.py:122: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'fecha entrada y salida son nulas' has dtype incompatible with timedelta64[ns], please explicitly cast to a compatible dtype first.\n",
      "  fact_novedades.loc[cond_both_null, 'TiempoResolucion'] = 'fecha entrada y salida son nulas'\n"
     ]
    }
   ],
   "source": [
    "# Copia base\n",
    "fact_novedades = novedades.copy()\n",
    "\n",
    "# -------- 1) TiempoKey --------\n",
    "fact_novedades['TiempoReporte'] = pd.to_datetime(fact_novedades['fecha_novedad'])\n",
    "fact_novedades['FechaReporteStr'] = fact_novedades['TiempoReporte'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Renombrar para que pandas las detecte bien\n",
    "dim_tiempo = dim_tiempo.rename(columns={\"Año\": \"year\", \"Mes\": \"month\", \"Dia\": \"day\"})\n",
    "\n",
    "# Crear columna de fecha\n",
    "dim_tiempo[\"fecha\"] = pd.to_datetime(dim_tiempo[[\"year\", \"month\", \"day\"]])\n",
    "dim_tiempo['FechaStr'] = dim_tiempo['fecha'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "fact_novedades = fact_novedades.merge(\n",
    "    dim_tiempo[['tiempo_key', 'FechaStr']], \n",
    "    left_on='FechaReporteStr', \n",
    "    right_on='FechaStr', how='left'\n",
    ").rename(columns={'tiempo_key':'TiempoKey'}).drop(columns=['FechaStr', 'FechaReporteStr'])\n",
    "\n",
    "# -------- 2) Atributos del tipo de novedad --------\n",
    "# Si 'categoria' y 'gravedad' NO existen en 'mensajeria_tiponovedad', primero verifica nombres\n",
    "print(\"Columnas en cat_tipo_nov:\", cat_tipo_nov.columns.tolist())\n",
    "\n",
    "fact_novedades = fact_novedades.merge(\n",
    "    servicios[['id', 'destino_id', 'cliente_id']],\n",
    "    left_on='servicio_id', right_on='id', how='left'\n",
    ").rename(columns={'destino_id':'destino_id_lookup','cliente_id':'cliente_id_serv'}) \n",
    "print(fact_novedades.columns.tolist())\n",
    "\n",
    "\n",
    "# Merge con destinos\n",
    "fact_novedades = fact_novedades.merge(\n",
    "    destinos[['id', 'ciudad_id', 'cliente_id']],\n",
    "    left_on='destino_id_lookup', right_on='id', how='left'\n",
    ").rename(columns={'ciudad_id':'ciudad_id_lookup','cliente_id':'cliente_id_lookup'})\n",
    "print(fact_novedades.columns.tolist())\n",
    "\n",
    "# Justo antes del merge con cat_tipo_nov\n",
    "tipo_dict = cat_tipo_nov.set_index('id')['nombre']\n",
    "fact_novedades['TipoNovedad'] = fact_novedades['tipo_novedad_id'].map(tipo_dict)\n",
    "\n",
    "\n",
    "# fact_novedades['CategoriaNovedad'] = pd.NA\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fact_novedades['Gravedad'] = pd.NA\n",
    "\n",
    "# Define un diccionario de gravedad\n",
    "grav_map = {\n",
    "    1: 'alta',\n",
    "    2: 'baja'\n",
    "}\n",
    "\n",
    "# Mapea según tipo_novedad_id\n",
    "fact_novedades['Gravedad'] = fact_novedades['tipo_novedad_id'].map(grav_map)\n",
    "\n",
    "\n",
    "\n",
    "# Usar el cliente asociado al servicio (cliente_id_serv)\n",
    "fact_novedades = fact_novedades.merge(\n",
    "    dim_cliente[['ClienteKey', 'cliente_id']],\n",
    "    left_on='cliente_id_serv',     # <— Lado izquierdo\n",
    "    right_on='cliente_id',         # <— Lado derecho en la dimensión\n",
    "    how='left'\n",
    ").drop(columns=['cliente_id'])     # Elimina duplicado si no lo necesitas\n",
    "print(fact_novedades.columns.tolist())\n",
    "\n",
    "\n",
    "fact_novedades = fact_novedades.merge(\n",
    "    dim_sede[['SedeKey', 'ciudad_id', 'cliente_id']],\n",
    "    left_on=['ciudad_id_lookup', 'cliente_id_lookup'],\n",
    "    right_on=['ciudad_id',       'cliente_id'],\n",
    "    how='left'\n",
    ").drop(columns=['ciudad_id', 'cliente_id'])  # ya no los necesitas del lado derecho\n",
    "print(fact_novedades.columns.tolist())\n",
    "\n",
    "\n",
    "# -------- 4) MensajeroKey --------\n",
    "fact_novedades = fact_novedades.merge(dim_mensajero[['MensajeroKey','user_id']],\n",
    "                                      left_on='mensajero_id', right_on='user_id', how='left')\n",
    "print(fact_novedades.columns.tolist())\n",
    "\n",
    "\n",
    "# -------- 5) Campos faltantes (por ahora NULL / default) --------\n",
    "# fact_novedades['TiempoResolucion'] = pd.NaT\n",
    "# 0) Asegúrate de tener cargada la tabla de medidas de tiempo:\n",
    "# medidas_tiempo = pd.read_sql_table('clientes_mensajeroaquitoy', url_bd)\n",
    "\n",
    "# 1) Merge de las fechas de entrada y salida (ajusta la llave si no es 'servicio_id')\n",
    "fact_novedades = fact_novedades.merge(\n",
    "    medidas_tiempo[['user_id', 'fecha_entrada', 'fecha_salida', 'salario']],\n",
    "    on='user_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 2) Convierte a datetime\n",
    "fact_novedades['fecha_entrada'] = pd.to_datetime(fact_novedades['fecha_entrada'])\n",
    "fact_novedades['fecha_salida']  = pd.to_datetime(fact_novedades['fecha_salida'])\n",
    "fact_novedades['year_entrada'] = fact_novedades['fecha_entrada'].dt.year\n",
    "\n",
    "\n",
    "# 3) Calcula el delta (queda NaT si falta alguna fecha)\n",
    "fact_novedades['TiempoResolucion'] = (\n",
    "    fact_novedades['fecha_salida'] - fact_novedades['fecha_entrada']\n",
    ")\n",
    "\n",
    "porc_map = {year: 0.10 + 0.02*(year - 2015) for year in range(2015, 2025)}\n",
    "\n",
    "fact_novedades['CostoAdicional'] = (\n",
    "    fact_novedades['salario'] * \n",
    "    fact_novedades['year_entrada'].map(porc_map)\n",
    ")\n",
    "\n",
    "# 4) Reemplaza los NaT por los mensajes según el caso\n",
    "cond_both_null   = fact_novedades['fecha_entrada'].isna() & fact_novedades['fecha_salida'].isna()\n",
    "cond_ent_null    = fact_novedades['fecha_entrada'].isna() & fact_novedades['fecha_salida'].notna()\n",
    "cond_sal_null    = fact_novedades['fecha_entrada'].notna() & fact_novedades['fecha_salida'].isna()\n",
    "\n",
    "fact_novedades.loc[cond_both_null, 'TiempoResolucion'] = 'fecha entrada y salida son nulas'\n",
    "fact_novedades.loc[cond_ent_null,  'TiempoResolucion'] = 'fecha de entrada es nula'\n",
    "fact_novedades.loc[cond_sal_null,  'TiempoResolucion'] = 'fecha de salida es nula'\n",
    "\n",
    "\n",
    "\n",
    "# 4) Si ya no necesitas las columnas originales, las puedes eliminar\n",
    "fact_novedades = fact_novedades.drop(\n",
    "    columns=['fecha_entrada', 'fecha_salida','salario', 'year_entrada'],\n",
    "    errors='ignore'\n",
    ")\n",
    "\n",
    "# fact_novedades['DuracionMinutos'] = pd.NA\n",
    "# fact_novedades['ImpactoEntrega'] = pd.NA\n",
    "# fact_novedades['RetrasoMinutos'] = pd.NA\n",
    "fact_novedades['Solucion'] = pd.NA\n",
    "\n",
    "\n",
    "# Asigna texto según Gravedad\n",
    "fact_novedades.loc[\n",
    "    fact_novedades['Gravedad'] == 'alta',\n",
    "    'Solucion'\n",
    "] = 'Escalar inmediatamente al equipo de soporte y priorizar resolución.'\n",
    "\n",
    "fact_novedades.loc[\n",
    "    fact_novedades['Gravedad'] == 'baja',\n",
    "    'Solucion'\n",
    "] = 'Registrar y programar en el próximo mantenimiento rutinario.'\n",
    "\n",
    "# 5) Contador de novedades por servicio y tipo\n",
    "fact_novedades['ContadorNovedad'] = (\n",
    "    fact_novedades\n",
    "      .groupby(['servicio_id','TipoNovedad'])['TipoNovedad']\n",
    "      .transform('count')\n",
    ")\n",
    "\n",
    "\n",
    "# — Renombra la descripción para que case con tu esquema —\n",
    "fact_novedades = fact_novedades.rename(\n",
    "    columns={'descripcion': 'Descripcion'}\n",
    ")\n",
    "\n",
    "# — Borra todo lo que sobró de los merges —\n",
    "to_drop = [\n",
    "    'id_x','id_y','id','user_id',\n",
    "    'ciudad_id_lookup','cliente_id_lookup','cliente_id_serv','destino_id_lookup'\n",
    "]\n",
    "fact_novedades = fact_novedades.drop(columns=to_drop, errors='ignore')\n",
    "\n",
    "\n",
    "# -------- 6) Columnas finales --------\n",
    "# cols = [\n",
    "#     'TiempoKey', 'MensajeroKey', 'ClienteKey', 'SedeKey',\n",
    "#     'TipoNovedad', 'CategoriaNovedad', 'Gravedad', 'Descripcion',\n",
    "#     'TiempoReporte', 'TiempoResolucion', 'DuracionMinutos',\n",
    "#     'ImpactoEntrega', 'RetrasoMinutos', 'Solucion', 'CostoAdicional',\n",
    "#     'ContadorNovedad'\n",
    "# ]\n",
    "# fact_novedades = fact_novedades[cols]\n",
    "\n",
    "cols = [\n",
    "    'TiempoKey', 'MensajeroKey', 'ClienteKey', 'SedeKey',\n",
    "    'TipoNovedad', 'Gravedad', 'Descripcion',\n",
    "    'TiempoReporte', 'TiempoResolucion', 'Solucion', 'CostoAdicional',\n",
    "    'ContadorNovedad'\n",
    "]\n",
    "fact_novedades = fact_novedades[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5273b573",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T13:21:55.049258Z",
     "start_time": "2024-11-05T13:21:55.040794Z"
    },
    "execution": {
     "iopub.execute_input": "2025-07-13T19:48:46.794933Z",
     "iopub.status.busy": "2025-07-13T19:48:46.794725Z",
     "iopub.status.idle": "2025-07-13T19:48:46.805872Z",
     "shell.execute_reply": "2025-07-13T19:48:46.805238Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fecha_novedad</th>\n",
       "      <th>tipo_novedad_id</th>\n",
       "      <th>descripcion</th>\n",
       "      <th>servicio_id</th>\n",
       "      <th>es_prueba</th>\n",
       "      <th>mensajero_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>51</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>1</td>\n",
       "      <td>Halo</td>\n",
       "      <td>51</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>51</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>51</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>51</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5203</th>\n",
       "      <td>5246</td>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>1</td>\n",
       "      <td>Facturaron el refrigerante equivocado, se hará...</td>\n",
       "      <td>28455</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204</th>\n",
       "      <td>5247</td>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>2</td>\n",
       "      <td>Edte drrvicio lo hace angelo</td>\n",
       "      <td>28464</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5205</th>\n",
       "      <td>5248</td>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>2</td>\n",
       "      <td>Edte lo hace csrlos</td>\n",
       "      <td>28467</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5206</th>\n",
       "      <td>5249</td>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>2</td>\n",
       "      <td>Este lohace csrlos</td>\n",
       "      <td>28466</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5207</th>\n",
       "      <td>5250</td>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>2</td>\n",
       "      <td>Este servicio rs moto csrguero</td>\n",
       "      <td>28467</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5208 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id fecha_novedad  tipo_novedad_id  \\\n",
       "0        4    2023-11-30                1   \n",
       "1        5    2023-11-30                1   \n",
       "2        6    2023-11-30                1   \n",
       "3        7    2023-11-30                1   \n",
       "4        8    2023-11-30                1   \n",
       "...    ...           ...              ...   \n",
       "5203  5246    2024-08-31                1   \n",
       "5204  5247    2024-08-31                2   \n",
       "5205  5248    2024-08-31                2   \n",
       "5206  5249    2024-08-31                2   \n",
       "5207  5250    2024-08-31                2   \n",
       "\n",
       "                                            descripcion  servicio_id  \\\n",
       "0                                                     A           51   \n",
       "1                                                  Halo           51   \n",
       "2                                                     A           51   \n",
       "3                                                     B           51   \n",
       "4                                                     A           51   \n",
       "...                                                 ...          ...   \n",
       "5203  Facturaron el refrigerante equivocado, se hará...        28455   \n",
       "5204                       Edte drrvicio lo hace angelo        28464   \n",
       "5205                                Edte lo hace csrlos        28467   \n",
       "5206                                 Este lohace csrlos        28466   \n",
       "5207                     Este servicio rs moto csrguero        28467   \n",
       "\n",
       "      es_prueba  mensajero_id  \n",
       "0          True             7  \n",
       "1          True             7  \n",
       "2          True             7  \n",
       "3          True             7  \n",
       "4          True             7  \n",
       "...         ...           ...  \n",
       "5203       True            27  \n",
       "5204       True            25  \n",
       "5205       True            25  \n",
       "5206       True            25  \n",
       "5207       True            25  \n",
       "\n",
       "[5208 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novedades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8789fa3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T19:48:46.808212Z",
     "iopub.status.busy": "2025-07-13T19:48:46.807920Z",
     "iopub.status.idle": "2025-07-13T19:48:56.787519Z",
     "shell.execute_reply": "2025-07-13T19:48:56.786924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "946"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7) Volcar fact_novedades al Data Warehouse\n",
    "fact_novedades.to_sql(\n",
    "    'fact_novedades',    # nombre de la tabla destino\n",
    "    cliente_etl,          # engine de SQLAlchemy apuntando al DW\n",
    "    if_exists='replace',  # reemplaza la tabla si ya existía\n",
    "    index=False           # no escribir el índice de pandas\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
