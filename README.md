

```markdown
# ETL de Mensajer√≠a - Carga de Hechos y Dimensiones

Este proyecto permite la ejecuci√≥n automatizada de notebooks de Jupyter para la carga de datos en una base de datos PostgreSQL. Se conecta a dos bases de datos: una fuente llamada `proyecto` y una base de datos destino llamada `proyectob`, donde se almacenan las **dimensiones** y los **hechos**.

## ‚öôÔ∏è Configuraci√≥n de la base de datos

Debes tener instalado PostgreSQL localmente y crear las siguientes bases de datos:

1. `proyecto` - Base de datos fuente, donde se extraen los datos.
2. `proyectob` - Base de datos destino, donde se almacenan las tablas de dimensiones y hechos.

Puedes crear las bases de datos desde pgAdmin o con comandos SQL como:

```sql
CREATE DATABASE proyecto;
CREATE DATABASE proyectob;
```

## üìÅ Archivo de configuraci√≥n

Edita el archivo `./configBD/config.yml` y aseg√∫rate de tener lo siguiente:

```yaml
mensajeria:
  driver: postgresql
  host: localhost
  port: 5432
  user: postgres
  password: Ec94
  db: proyecto

bodega:
  driver: postgresql+psycopg2
  host: localhost
  port: 5432
  user: postgres
  password: Ec94
  db: proyectob
```

Ajusta el usuario, contrase√±a o puertos si tu configuraci√≥n de PostgreSQL es diferente.

## üêç activar entorno virtual

activa el entorno virtual (en terminal Bash):

```bash
source venv/Scripts/activate
```

En PowerShell (Windows):

```powershell
.\venv\Scripts\Activate.ps1
```

## üì¶ Instalar dependenciass

Aseg√∫rate de tener el archivo `requirements.txt` en la ra√≠z del proyecto con el siguiente contenido:

```txt
asyncio
PyYAML
psycopg2
sqlalchemy
jupyter
nbconvert
jupyter_client
jupyter_core
pandas
```

Instala las dependencias con:

```bash
pip install -r requirements.txt
```

## ‚ñ∂Ô∏è Ejecutar el script principal

Con el entorno activado y PostgreSQL funcionando, ejecuta:

```bash
python main.py
```

Este script:
- Limpia las tablas de la base de datos de destino si es necesario
- Ejecuta notebooks de Jupyter que crean y cargan las tablas de dimensiones y hechos
- Ejecuta scripts SQL finales definidos en `sqlscripts.yml`

## ‚úÖ Requisitos previos

- Python 3.8 o superior
- PostgreSQL en funcionamiento (con las bases `proyecto` y `proyectob`)
- Visual Studio Code (opcional, recomendado)
- Librer√≠as Python listadas en `requirements.txt`

## üìå Notas

- Aseg√∫rate de que `jupyter` est√© instalado correctamente para ejecutar notebooks
- Verifica que los archivos `.ipynb` est√©n en las rutas correctas (`mensajeria/dimensiones/` y `mensajeria/hechos/`)
- Si PostgreSQL requiere SSL, el `sslmode=require` est√° configurado autom√°ticamente en el script








# Explicaci√≥n de los Archivos Modificados

## üìú sqlscripts.yml

Este archivo YAML contiene scripts SQL mejorados para la gesti√≥n de la base de datos del Data Warehouse. Su estructura y prop√≥sito son:

### 1. **setup_cleanup**
- **Prop√≥sito**: Preparaci√≥n inicial de la base de datos.
- **Contenido**:
  - Elimina constraints existentes (PKs y FKs) de las tablas de hechos para evitar conflictos.
  - Corrige tipos de datos clave (como BIGINT) para garantizar compatibilidad.
  - Maneja casos donde las columnas pueden tener valores nulos durante la transformaci√≥n.

### 2. **dimensions_pk**
- **Prop√≥sito**: Establece las llaves primarias en las tablas de dimensiones.
- **Caracter√≠sticas**:
  - A√±ade constraints PRIMARY KEY a `dim_cliente`, `dim_mensajero`, `dim_sede` y `dim_tiempo`.
  - No modifica la estructura existente de las dimensiones.

### 3. **facts_pk**
- **Prop√≥sito**: Estrategia mejorada para PKs en tablas de hechos.
- **Innovaciones**:
  - Crea columnas artificiales (`servicio_id`, `NovedadKey`) como SERIAL para PKs robustas.
  - √çndices √∫nicos para controlar duplicados naturales (`idx_servicio_unico`).
  - Comentarios descriptivos para documentaci√≥n autom√°tica.

### 4. **facts_fk_servicios/facts_fk_novedades**
- **Prop√≥sito**: Define las relaciones entre hechos y dimensiones.
- **Detalles**:
  - Constraints FOREIGN KEY que vinculan `fact_servicios` y `fact_novedades` con las dimensiones.
  - Referencias a `tiempo_key`, `ClienteKey`, `SedeKey`, etc.

### 5. **etl_strategy**
- **Prop√≥sito**: L√≥gica avanzada para el proceso ETL.
- **Componentes clave**:
  - Tabla de staging (`stg_servicios`) con columna `accion` para control de cambios.
  - Funci√≥n `carga_servicios()` para carga incremental con detecci√≥n de duplicados.
  - Funci√≥n `limpiar_duplicados_servicios()` para limpieza de registros redundantes.

---

## üêç main.py

Script principal con mejoras significativas:

### 1. **Manejo de conexiones**
- **Nuevo**: Conexiones flexibles con soporte SSL condicional (`require_ssl`).
- **Resiliencia**: Reintenta sin SSL si falla la conexi√≥n segura.

### 2. **Funciones clave**
- **`run_notebook()`**: Ejecuta notebooks usando `nbconvert` con el mismo int√©rprete de Python.
- **`check_data_changes()`** (placeholder): L√≥gica para detectar cambios en los datos fuente.
- **`clean_etl_tables()`**: Limpieza segura de tablas usando transacciones.

### 3. **Flujo mejorado**
1. **Pre-ETL**: Verifica estado de la BD y datos.
2. **Ejecuci√≥n**: Procesa notebooks en orden (dimensiones ‚Üí hechos).
3. **Post-ETL**: Ejecuta scripts SQL de `sqlscripts.yml` con manejo de errores por secci√≥n.

### 4. **Manejo de errores**
- Rollback autom√°tico en fallos.
- Continuaci√≥n tras errores en notebooks individuales.

---

## üìä hecho_servicios.ipynb

Notebook especializado en la tabla de hechos de servicios:

### Proceso ETL
1. **Extracci√≥n**: 
   - Datos de `mensajeria_servicio`, `mensajeria_origenservicio`, etc.
   - Dimensiones desde el DW (`dim_cliente`, `dim_sede`).

2. **Transformaci√≥n**:
   - **Tiempos**: Calcula duraciones entre fases (asignaci√≥n, recogida, entrega).
   - **Eficiencia**: M√©trica basada en tiempo promedio por mensajero.
   - **Prioridades**: Mapeo de valores como `Alta: En una Hora` a minutos.

3. **Carga**:
   - Subconjunto de 5,000 registros a `fact_servicios`.
   - Consultas anal√≠ticas predefinidas (ej: eficiencia por mensajero).

### Validaciones
- Verificaci√≥n de nulos en timestamps.
- Imputaci√≥n de medianas para duraciones faltantes.

---

## ‚ö†Ô∏è hecho_novedades.ipynb

Notebook para hechos de novedades:

### Flujo clave
1. **Enriquecimiento**:
   - Merge con `dim_tiempo` usando `fecha_novedad`.
   - Clasificaci√≥n de gravedad (`alta`/`baja`) seg√∫n `tipo_novedad_id`.

2. **L√≥gica de resoluci√≥n**:
   - Asigna soluciones autom√°ticas basadas en gravedad.
   - Calcula `CostoAdicional` seg√∫n a√±o y salario del mensajero.

3. **Manejo temporal**:
   - Detecta casos especiales (ej: "fecha entrada y salida son nulas").
   - Conversi√≥n robusta a `timedelta`.

### Output
- Tabla `fact_novedades` con m√©tricas como `ContadorNovedad`.

---

## Impacto Conjunto

Estos cambios proporcionan:
‚úîÔ∏è **Mayor robustez**: Manejo de errores y duplicados.  
‚úîÔ∏è **Documentaci√≥n embebida**: Comentarios en SQL y YAML.  
‚úîÔ∏è **Flexibilidad**: Conexiones con/sin SSL.  
‚úîÔ∏è **Escalabilidad**: Carga incremental v√≠a funciones PL/pgSQL.



```

  
